# ðŸŽ¬ GPTBuddyAI Demo Queries - Jan 1, 2026

**Purpose**: Pre-tested queries that showcase system capabilities
**Audience**: Investors (technical + business)
**Duration**: 2-3 minutes total

---

## ðŸŽ¯ The 5 Demo Queries

### **Query 1: Personal Knowledge Discovery** (30 sec)
**Category**: Conversation Insights
**Tab**: Tab 2 (RAG Query)

**Question**:
```
What are the main themes I've explored about AI ethics and regulation over the past 2 years?
```

**Why This Works**:
- Shows personal knowledge distillation
- Demonstrates cross-temporal analysis (2023-2025)
- Highlights topic discovery capability
- **Investor Hook**: "This AI mapped my entire intellectual journey"

**Expected Result**:
- Mix of Chat messages about EU AI Act, ethical arbitration, AGI convergence
- Should cite multiple conversation dates
- Shows thematic consistency in your thinking

---

### **Query 2: NIST Compliance Reference** (30 sec)
**Category**: Professional/Enterprise Use Case
**Tab**: Tab 2 (RAG Query)

**Question**:
```
What is the current guidance around establishing digital identity and what are the identity assurance levels?
```

**Why This Works**:
- Demonstrates NIST expertise (337 documents)
- Shows precise regulatory retrieval
- Technical depth (IAL 1-3 framework)
- **Investor Hook**: "Enterprise-ready compliance AI"

**Expected Result**:
- NIST SP 800-63-4 (Digital Identity Guidelines, Aug 2024)
- Identity Assurance Levels (IAL 1, 2, 3)
- Identity proofing requirements
- Should cite pages 13, 7, specific sections

---

### **Query 3: Zero Trust Architecture** (30 sec)
**Category**: Cutting-Edge Security Topic
**Tab**: Tab 2 (RAG Query)

**Question**:
```
Explain the core principles of zero trust architecture according to NIST
```

**Why This Works**:
- Hot topic in cybersecurity (2024-2025)
- Shows depth of NIST library (SP 800-207, SP 1800-35)
- Demonstrates multi-document synthesis
- **Investor Hook**: "Instant expert-level answers"

**Expected Result**:
- NIST SP 800-207 (Zero Trust Architecture)
- Seven tenets of zero trust
- Implementation guidance
- Should mention "never trust, always verify"

---

### **Query 4: Cross-Corpus Synthesis** (45 sec)
**Category**: Advanced Intelligence (The "Wow" Moment)
**Tab**: Tab 2 (RAG Query)

**Question**:
```
How do my thoughts on privacy and digital sovereignty align with NIST's privacy controls in SP 800-53?
```

**Why This Works**:
- **Most impressive query** - combines personal + reference knowledge
- Shows AI reasoning across corpora
- Reveals gaps/alignment in thinking
- **Investor Hook**: "This is where personal insight meets regulatory intelligence"

**Expected Result**:
- Mix of your Chat messages about privacy/sovereignty
- NIST SP 800-53 privacy controls (P family)
- Should identify alignments (e.g., "Your emphasis on local control aligns with NIST UL-1")
- May identify areas where NIST goes further or you're ahead

---

### **Query 5: Multifactor Authentication Deep Dive** (30 sec)
**Category**: Technical Depth
**Tab**: Tab 2 (RAG Query)

**Question**:
```
What are the specific requirements for multifactor authentication in e-commerce according to NIST?
```

**Why This Works**:
- Specific, practical use case
- Shows granular NIST guidance (SP 1800-17)
- Demonstrates citation accuracy
- **Investor Hook**: "From high-level strategy to implementation details in 3 seconds"

**Expected Result**:
- NIST SP 1800-17 (MFA for E-Commerce)
- FIDO U2F implementations
- Risk-based authentication approaches
- Specific control requirements

---

## ðŸŽ¨ Demo Flow Recommendations

### **Option A: Quick Demo (2 minutes)**
1. Query 1 (Personal insights) - 30s
2. Query 2 (NIST reference) - 30s
3. Query 4 (Cross-corpus synthesis) - 45s
4. Show Tab 1 topic map - 15s

**Total**: ~2 minutes
**Impact**: High - shows range without overwhelming

---

### **Option B: Deep Dive (3-4 minutes)**
1. **Tab 1 intro** (30s): "AI discovered 25 topics in 55K messages"
2. **Query 1** (30s): Personal knowledge
3. **Tab 3 reveal** (20s): "337 NIST documents, 32K pages"
4. **Query 2** (30s): NIST reference
5. **Query 3** (30s): Zero trust (show depth)
6. **Query 4** (45s): Cross-corpus (the climax)
7. **Wrap** (15s): "All local, no cloud, no privacy risk"

**Total**: ~3:30
**Impact**: Very high - tells complete story

---

### **Option C: Technical Audience (5 minutes)**
- All 5 queries
- Show query settings (top-k, max tokens)
- Briefly mention architecture (ChromaDB, MLX-LM, sentence-transformers)
- Show topic visualization in detail
- Discuss expandability (add more corpora)

---

## ðŸŽ¯ Backup Queries (If Needed)

### **Backup 1: Technical Project Query**
```
What Python development projects have I worked on and what were the main technical challenges?
```
**Use Case**: If investor is technical and asks about your work

### **Backup 2: Privacy Controls**
```
What are the NIST privacy controls for data minimization and how should they be implemented?
```
**Use Case**: If conversation shifts to privacy/compliance

### **Backup 3: AI Regulation**
```
Summarize my analysis of the EU AI Act and its implications
```
**Use Case**: If discussing AI policy/regulation

---

## âš¡ Pro Tips for Demo Day

### **Before You Start**:
1. âœ… Open UI in incognito/fresh tab (clean slate)
2. âœ… Zoom to 125-150% for visibility
3. âœ… Close all other tabs
4. âœ… Have this file open on second monitor/phone
5. âœ… Test all 5 queries once in the morning

### **During Demo**:
1. **Speak while it searches**: "The system is searching 60,000 chunks..."
2. **Read citations aloud**: "SP 800-63-4, August 2024..."
3. **Scroll through answer**: Don't just show, narrate
4. **Point to source icons**: "See - this is from my conversations ðŸ’¬, this is NIST ðŸ“„"
5. **Emphasize speed**: "3 seconds to search 337 documents"

### **If Something Goes Wrong**:
- **Query fails**: "Let me try a different question" â†’ Use backup query
- **Slow response**: "The LLM is generating..." â†’ Totally normal
- **Wrong results**: Pivot to topic map â†’ "But look at what it discovered..."
- **UI crash**: Have screenshots in slides as fallback

---

## ðŸ“Š Expected Performance

| Metric | Target | Actual (Test) |
|--------|--------|---------------|
| Query latency | <5s | TBD - test today |
| Result relevance | >80% | TBD - test today |
| Citation accuracy | 100% | TBD - test today |
| UI load time | <3s | âœ… (tested) |

**Action Item**: Run all 5 queries NOW and verify results

---

## ðŸŽ¤ Suggested Narrative

### **Opening** (15 seconds):
> "I want to show you something I've been building. GPTBuddyAI is my personal AI assistant that analyzed 2 years of my conversationsâ€”55,000 messagesâ€”and combined them with 337 NIST compliance documents. Everything runs locally on this laptop."

### **After Query 1** (5 seconds):
> "Notice how it synthesized themes across 2 years of thinkingâ€”something I couldn't do manually."

### **After Query 2** (5 seconds):
> "Now watch it switch contexts entirelyâ€”from personal to professional regulatory guidance."

### **After Query 4** (10 seconds):
> "This is the magic moment. It's comparing my personal philosophy with official NIST standards and finding alignments and gaps. This is the future of knowledge work."

### **Closing** (20 seconds):
> "What you just saw: 60,000 searchable passages, instant expert-level answers, perfect citations, zero privacy risk. Now imagine this for your organization's institutional memory. Contracts, policies, employee knowledgeâ€”all searchable, all private, all yours."

---

## ðŸš€ Investor Questions - Prepared Answers

**Q**: "How accurate is it?"
**A**: "The retrieval is deterministicâ€”citations are always correct. The LLM synthesis quality depends on the model. Right now I'm using SmolLM2 for privacy, but it's swappableâ€”could use GPT-4, Claude, or fine-tuned models."

**Q**: "Can it handle more data?"
**A**: "Absolutely. Vector databases scale to millions of documents. I'm at 60K chunksâ€”could easily go to 1M+ with the same architecture."

**Q**: "What about cost?"
**A**: "Zero ongoing cost. It runs on my laptop. For cloud deployment, it's infrastructure onlyâ€”no API fees since we're using local LLM inference."

**Q**: "How long did this take to build?"
**A**: "The MVP took 10 days. But the architecture is modularâ€”adding new data sources is hours, not weeks."

**Q**: "What's next?"
**A**: "Phase 2: Hierarchical topics, timeline visualization, multi-user support. Imagine a company where every employee can query 10 years of institutional knowledge."

---

**Status**: Ready to test! Run these 5 queries and verify results. âœ…
